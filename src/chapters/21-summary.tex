%&../settings/preamble.main

\ifsubfile
% ATTENTION non modificare "development", viene modificata automaticamente in deploy
\newcommand{\docversion}{development}
\usepackage{../settings/subfile}
\setcounter{chapter}{20}

% arara: pdflatex: { options: ["--output-directory=../build"], shell: yes, draft: yes, synctex: no }
% arara: pdflatex: { options: ["--output-directory=../build"], shell: yes, synctex: no }
\begin{document}
\fi
\chapter{Riassunto}
\tagThisPage

\section*{Analisi della complessità}

\subsection*{Metodo dell'esperto (o delle ricorrenze comuni)}

\begin{theorem}[ricorrenze lineari con partizione bilanciata]
Siano \(a\) e \(b\) costanti intere tali che \(a \geqslant 1\) e \(b \geqslant 2\), e \(c\), \(\beta\) costanti reali tali che \(c > 0\) e \(\beta \geqslant 0\).
Sia \(T(n)\) data dalla relazione di ricorrenza:
\[
	T(n) =
	\begin{dcases}\textstyle
		a\T{\frac{n}{b}} + cn^{\beta} & n > 1 \\
		d & n \leqslant 1 \\
	\end{dcases}
\]
Posto \(\alpha = \frac{\log a}{\log b} = \log_{b} a\), allora:
\[
	T(n) =
	\begin{dcases}
		\Theta(n^{\alpha}) & \alpha > \beta \\
		\Theta(n^{\alpha}\log n) & \alpha = \beta \\
		\Theta(n^{\beta}) & \alpha < \beta \\
	\end{dcases}
\]
\end{theorem}

\begin{theorem}[ricorrenze lineari con partizione bilanciata estesa]
Sia \(a \geqslant 1\), \(b > 1\), \(f(n)\) asintoticamente positiva, e sia
\[
	T(n) =
	\begin{dcases}\textstyle
		a\T{\frac{n}{b}} + f(n) & n > 1 \\
		d & n \leqslant 1 \\
	\end{dcases}
\]
Sono dati tre casi:
\begin{enumerate}
	\item \(\exists \varepsilon > 0 \colon f(n) = \Omicron(n^{\alpha-\varepsilon})\) allora \(T(n) = \Theta(n^{\alpha})\);
	\item \(f(n) = \Theta(n^\alpha)\) allora \(T(n) = \Theta(f(n)\log n)\);
	\item \(\exists \varepsilon > 0 \,\colon f(n) = \Omicron(n^{\alpha + \varepsilon}) \land\\\exists c \,\colon 0 < c < 1, \exists m > 0 \,\colon\\a f(\frac{n}{b}) \leqslant c f(n), \forall n \geqslant m\) allora \(T(n) = \Theta(f(n))\).
\end{enumerate}
\end{theorem}
\begin{theorem}[ricorrenze lineari di ordine costante]
Siano \(\{a_1, a_2, \dots, a_n\}\) costanti intere non negative, con \(h\) costante positiva, \(c\) e \(\beta\) costanti reali tali che \(c > 0\) e \(\beta \geqslant 0\), e sia \(T(n)\) definita dalla relazione di ricorrenza:
\[
	T(n) =
	\begin{dcases}
		\sum_{1 \leqslant i \leqslant h} a_i \T{n-1} + cn^{\beta} & n > m \\
		\Theta(1) & n \leqslant m \leqslant h \\
	\end{dcases}
\]
Posto \(a = \sum_{1 \leqslant i \leqslant h} a_i\), allora:
\begin{enumerate}
	\item \(T(n)\) è \(\Theta(n^{\beta+1})\), se \(a = 1\);
	\item \(T(n)\) è \(\Theta(a^n n^{\beta})\), se \(a \geqslant 2\).
\end{enumerate}
\end{theorem}

\href{https://www.bigocheatsheet.com/}{Big-O Complexity Cheatsheet {\ExternalLink}}

\section*{Strutture dati}

\begin{algorithm}[H]
	\caption[]{Specifica \textsc{Sequence}}
	\input{sequence-interface}
\end{algorithm}

\begin{algorithm}[H]
	\caption[]{Struttura dati \textsc{Set}}
	\input{set-interface}
\end{algorithm}

\begin{algorithm}[H]
	\caption[]{Specifica \textsc{Dictionary}}
	\input{dict-interface}
\end{algorithm}

\begin{algorithm}[H]
	\caption[]{Struttura dati lista bidirezionale con sentinella}
	\input{list-pseudocode}
\end{algorithm}

\begin{algorithm}[H]
	\caption[]{Specifica \textsc{Stack}}
	\input{stack-interface}
\end{algorithm}

\begin{algorithm}[H]
	\caption[]{Specifica \textsc{Stack}}
	\input{stack-interface}
\end{algorithm}

\begin{algorithm}[H]
	\caption[]{Specifica \textsc{Queue}}
	\input{queue-interface}
\end{algorithm}

\begin{algorithm}[H]
	\caption[]{Struttura dati coda basata su vettore circolare}
	\input{queue-pseudocode}
\end{algorithm}

\section*{Risoluzione di problemi}

Dato un problema non esistono \enquote{ricette originali} per risolverlo in modo efficiente;
tuttavia è possibile evidenziare quattro fasi:
\begin{enumerate}
	\item \textbf{classificazione del problema}: è il primo passo verso la risoluzione;
	\item \textbf{caratterizzazione della soluzione}: bisogna caratterizzare matematicamente la soluzione, evitando di escludere soluzioni banali;
	\item \textbf{tecnica di progetto}: quando è possibile dividere il problema in più sottoproblemi di complessità minore allora la tecnica \enquote{divide et impera} potrebbe essere quella più appropriata (più avanti vedremo delle tecniche più interessanti quali: programmazione dinamica (Capitolo 13), algoritmi ingordi (Capitolo 14) e backtrack (Capitolo 16));
	\item \textbf{utilizzo di strutture dati}: bisogna scegliere la struttura dati più adatta alla risoluzione del nostro particolare problema (spesso sarà una tabella hash o un albero binario di ricerca, più avanti vedremo delle strutture dati specializzate per risolvere problemi specifici, a differenza di quelle che abbiamo visto fin'ora che sono generiche).
\end{enumerate}
Queste fasi non sono necessariamente sequenziali, l'ordine dipende da come stiamo affrontando il problema.

\subsection*{Classificazione dei problemi}

Ma come possiamo classificare un problema?
Le classi di problemi che affronteremo possono essere raggruppate in quattro macro-categorie:
\begin{itemize}
	\item \textbf{problemi decisionali}: consistono nel determinare se il dato in ingresso soddisfa o meno una certa proprietà ed hanno una risposta binaria (si/no, true/false); come ad esempio stabilire se un grafo risulta connesso o meno.
	Su questo genere di problemi spesso non esistono delle tecniche standard e bisogna creare algoritmi ad-hoc;
	\item \textbf{problemi di ricerca}: consistono nel trovare nello spazio di soluzioni possibili una soluzione ammissibile che rispetti certi vincoli, come ad esempio la ricerca della posizione di una sottostringa in una stringa.
	In questi problemi la tecnica \enquote{divide et impera} può rincorrere in nostro aiuto;
	\item \textbf{problemi di ottimizzazione}: ad ogni soluzione è associata una funzione di costo e vogliamo trovare quella di costo minimo, come ad esempio il cammino (pesato) più breve fra due nodi.
	Questa classe di problemi può essere risolta tramite la programmazione dinamica o algoritmi ingordi;
	\item \textbf{problemi di approssimazione}: a volte, trovare la soluzione ottima è computazionalmente impossibile e ci si accontenta di una soluzione approssimata, in questo caso il costo rimane basso ma non sappiamo se è ottimale; un esempio di questo genere di problemi è quello del commesso viaggiatore.
\end{itemize}

\subsection*{Caratterizzazione della soluzione}

\`{E} fondamentale definire bene il problema dal punto di vista matematico.
La formulazione del problema può suggerire una prima idea, seppur banale, alla risoluzione dello stesso.
Lo si può osservare nella formulazione del seguente problema: data una sequenza di \(n\) elementi, una permutazione ordinata è data dal minimo seguito da una permutazione ordinata dei restanti \(n-1\) elementi.
Questa formulazione produce l'algoritmo \selectionSort.
La definizione matematica può suggerire una possibile tecnica, ad esempio:
\begin{itemize}
	\item se troveremo una \emph{sottostruttura ottima} allora potremmo applicare la programmazione dinamica (Capitolo 13);
	\item se troveremo la \emph{proprietà greedy} allora potremmo applicare un algoritmo ingordo (Capitolo 14).
\end{itemize}

\section*{Tecniche di soluzione dei problemi}

Come vengono affrontati i problemi dalle varie tecniche?
\begin{itemize}
	\item nella \textbf{tecnica divide-et-impera} un problema viene suddiviso in sotto-problemi indipendenti, i quali vengono risolti ricorsivamente (avendo quindi un approccio dall'alto verso il basso, detto \foreign{top-down}); Abbiamo già visto diversi esempi dell'applicazione di questa tecnica, provate a pensare all'algoritmo \mergeSort: ordinare due sottovettori sono due problemi indipendenti (ordinare il sottovettore di sinistra non richiede conoscere il contenuto del vettore di destra e viceversa);
	\item nella \textbf{programmazione dinamica} la soluzione viene costruita (dal basso verso l'altro, \foreign{bottom-up}) a partire da un insieme di sotto-problemi potenzialmente ripetuti.
	\item la tecnica della \foreign{memoization} (annotazione) è la versione \foreign{top-down} della programmazione dinamica.
	\begin{figure}[H]
        \centering
        \includegraphics[width=.65\textwidth]{progrdyn}
    \end{figure}
	\item la \textbf{tecnica \foreign{greedy}} effettua sempre la scelta localmente ottima (necessita di una dimostrazione).
	\item il \textbf{backtrack} procede per \enquote{tentativi}, tornando ogni tanto sui suoi passi;
	\item nella ricerca locale la soluzione ottima viene trovata \enquote{migliorando} via via soluzioni esistenti; Negli \textbf{algoritmi probabilistici} si dimostra che talvolta è meglio scegliere casualmente, ma in modo \enquote{gratuito}, che con giudizio, ma in maniera costosa.
\end{itemize}

\section*{La tecnica del Dividi-et-Impera}

La tecnica del Divide-et-Impera si suddivide in tre fasi principali:
\begin{itemize}
	\item \textbf{Divide}: divide il problema in sotto-problemi più piccoli è indipendenti;
	\item \textbf{Impera}: risove i sottoproblemi ricorsivamente;
	\item (\textbf{Combina}): \enquote{unisce} le soluzioni dei sottoproblemi.
\end{itemize}

\subsection*{Algoritmi Dividi-et-Impera}

\begin{algorithm}[H]
	\caption{mergeSort}
	\input{mergeSort}
	\input{merge}
\end{algorithm}

\begin{algorithm}[H]
	\caption{quickSort}
	\input{quickSort}
	\input{quickSort-pivot}
\end{algorithm}

\section*{Algoritmi di programmazione dinamica con \emph{memoization}}

\subsection*{Hateville}

\paragraph{Descrizione del problema}
Hateville è un villaggio particolare, composto da \(n\) case, numerate da \(1\) a \(n\) lungo una singola strada.
Ad Hateville ognuno odia i propri vicini della porta accanto, da entrambi i lati.
Quindi il vicino \(i\) odia i vicini \(i-1\) e \(i+1\) (se esistenti).
Hateville vuole organizzare una sagra e vi ha affidato il compito di raccogliere i fondi.
Ogni abitante \(i\) ha intenzione di donare una quantità \(D[i]\), ma non intende partecipare ad una raccolta fondi a cui partecipano uno o entrambi i propri vicini.

Dobbiamo scrivere un algoritmo che restituisca la quantità massima di fondi che può essere raccolta.

\subsubsection*{Soluzione}

\[
    DP[i] =
    \begin{dcases}
        0                                  & i = 0 \\
        D[1]                               & i = 1 \\
    \maxFunction(DP[i-1], DP[i-2] + DP[i]) & i \geqslant 2 \\
    \end{dcases}
\]

\begin{algorithm}[H]
    \caption{Ricostruire la soluzione generale di Hateville}
    \input{hateville-solution}
\end{algorithm}

\subsection*{Zaino}

\paragraph{Definizione formale del problema}
Dati un vettore \(w\), dove \(w[i]\) è il \textbf{peso} (\foreign{weight}) dell'oggetto \(i\)-esimo, un vettore \(p\), dove \(p[i]\) è il \textbf{profitto} (\foreign{profit}) dell'oggetto \(i\)-esimo, e la \textbf{capacità} \(C\) dello zaino.
Bisogna trovare un insieme \(S \subseteq \{1, \dots, n\}\) tale che:
\begin{itemize}
    \item il \textbf{valore totale} deve essere minore o uguale alla capacità;
    \[w(S) = \sum_{i \in S} w[i] \leqslant C\]
    \item il \textbf{profitto totale} deve essere massimizzato.
    \[p(S) = \sum_{i \in S} p[i]\]
\end{itemize}

\subsubsection*{Soluzione}

Se \textbf{non prendo} quell'oggetto la capacità non cambia e non c'è profitto.
Avanzo semplicemente con l'indice (\(i-1\)).
Se \textbf{prendo} quell'oggetto sottraiamo il peso dalla capacità (\(c - w[i]\)) e aggiungiamo il relativo profitto (\(+ p[i]\)).
Avanzo con l'indice (\(i-1\)).
Se non abbiamo più oggetti o se abbiamo finito la capacità dello zaino allora il nostro guadagno sarà \(0\).
Per evitare di prendere un oggetto quando la capacità diventerebbe negativa mettiamo come valore convenzionale \(-\infty\).

\[
    DP[i][c] =
    \begin{dcases}
        0                                                   & i=0\ \Or\ c=0     \\
        -\infty                                             & c<0               \\
        \maxFunction(DP[i-1][c - w[i]] + p[i], DP[i-1][c])  & \text{altrimenti} \\
    \end{dcases}
\]

\begin{algorithm}[H]
    \caption{Algoritmo \emph{iterativo} per la soluzione al problema dello zaino}
    \input{knapsack-dp}
\end{algorithm}

\paragraph{Complessità}
La complessità di \knapsack è \(\Theta(nC)\).
Osserviamo che \(C\) è parte dell'input (non è la dimensione del problema).
Applicchiamo quindi il criterio di costo logaritmico: per rappresentare \(C\) sono necessari \(k = \log_2 C\) bit, quindi la complessità è \(T(n) = \Omicron(n2^k)\). \knapsack è un algoritmo esponenziale.

\begin{algorithm}[H]
    \caption{Algoritmo \emph{ricorsivo} per la soluzione al problema dello zaino}
    \input{knapsack-recursive}
\end{algorithm}

\paragraph{Complessità}
Non è detto che tutti gli elementi debbano essere riempiti.
La complessità in spazio è pari a \(\Theta(C)\).

\subsection*{Zaino senza limiti}

Dato uno zaino senza limiti di scelta di capacità \(C\) e \(n\) oggetti caratterizzati da peso \(w\) e profitto \(p\), definiamo \(DP[c]\) come il massimo profitto che può essere ottenuto da tali oggetti in uno zaino di capacità \(c \leqslant C\).

\[
    DP[c] =
    \begin{dcases}
    0                                           & c = 0 \\
    \max_{w[i] \leqslant c}\{DP[c-w[i]] + p[i]\} & c > 0 \\
    \end{dcases}
\]

\begin{algorithm}[H]
    \caption{Zaino senza limiti con \foreign{memoization} e ricostruzione della soluzione}
    \input{knapsack-limitless-memo-solution}
\end{algorithm}

\paragraph{Analisi della complessità}
Ognuno degli elementi costa \(\Theta(n)\) per essere riempito, mal che vada devo riempire tutte le \(C\) caselle delle tabelle.
Quindi nel caso pessimo ho una complessità di \(\Omicron(nC)\)

\ifsubfile
\end{document}
\fi